{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_text_by_time_window(result: dict, duration: int, time_window_size: int = 30):\n",
    "    \"\"\"\n",
    "    Group text output from OpenAI whisper into time windows\n",
    "    :param result: dict, output from OpenAI whisper model\n",
    "    :param time_window_size: int, size of time window in seconds\n",
    "\n",
    "    :return: dict, start time in seconds as key, text as value\n",
    "    \"\"\"\n",
    "    # get transcript segments and their start times\n",
    "    seg_starts = [seg[\"start\"] for seg in result[\"segments\"]]\n",
    "    seg_text = [seg[\"text\"] for seg in result[\"segments\"]]\n",
    "\n",
    "    time_windows = {}\n",
    "\n",
    "    # group text into buckets\n",
    "    for time, text in zip(seg_starts, seg_text):\n",
    "        time_window = int(time // time_window_size)\n",
    "\n",
    "        if time_window not in time_windows:\n",
    "            time_windows[time_window] = [text]\n",
    "        else:\n",
    "            time_windows[time_window].append(text)\n",
    "    final_times = {}\n",
    "\n",
    "    # create lists of start and ends times\n",
    "    starts = [index * time_window_size for index in time_windows.keys()]\n",
    "    ends = starts[1:] + [duration]\n",
    "\n",
    "    final_result = []\n",
    "\n",
    "    # create list of texts with startime and end timex\n",
    "    for ((index, text), (start, end)) in zip(time_windows.items(), zip(starts, ends)):\n",
    "        final_result.append({\"start\": start, \"end\": end, \"text\": \"\".join(text)})\n",
    "\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2265f414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "filename = \"audio.mp3\"\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    url = \"https://nyt.simplecastaudio.com/3026b665-46df-4d18-98e9-d1ce16bbb1df/episodes/dd430a54-e475-46bd-b9fb-97a359c4161c/audio/128/default.mp3/default.mp3_ywr3ahjkcgo_63f2a6a9bc78a0a3100fbc9a815bf42d_62565420.mp3?aid=rss_feed&amp;awCollectionId=3026b665-46df-4d18-98e9-d1ce16bbb1df&amp;awEpisodeId=dd430a54-e475-46bd-b9fb-97a359c4161c&amp;feed=82FI35Px&hash_redirect=1&x-total-bytes=62565420&x-ais-classified=unclassified&listeningSessionID=0CD_382_16__be48a1539bfd29c334b850a7a8cf37e16ec362de\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "print(\"File downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "806e8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define the filename for pickling\n",
    "pickle_filename = \"transcription_obj.pickle\"\n",
    "\n",
    "# Check if the pickled file exists\n",
    "if os.path.exists(pickle_filename):\n",
    "    # Read the pickled file\n",
    "    with open(pickle_filename, \"rb\") as file:\n",
    "        transcription_obj = pickle.load(file)\n",
    "else:\n",
    "\n",
    "    import whisper\n",
    "    model = whisper.load_model(\"base\")\n",
    "    transcription_obj = model.transcribe(\"audio.mp3\", language='en', without_timestamps=True)\n",
    "    \n",
    "    with open(pickle_filename, \"wb\") as file:\n",
    "        pickle.dump(transcription_obj, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a6f4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcript.txt', 'w') as file:\n",
    "    file.write(transcription_obj['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "42822593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import\n",
    "# from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# from langchain_community.embeddings.sentence_transformer import (\n",
    "#     SentenceTransformerEmbeddings,\n",
    "# )\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# # load the document and split it into chunks\n",
    "# loader = TextLoader(\"transcript.txt\")\n",
    "# documents = loader.load()\n",
    "\n",
    "\n",
    "# # split it into chunks\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# # print(len(docs[0].page_content))\n",
    "# print(docs)\n",
    "\n",
    "\n",
    "\n",
    "# # # create the open-source embedding function\n",
    "# # embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# # # load it into Chroma\n",
    "# # db = Chroma.from_documents(docs, embedding_function)\n",
    "\n",
    "# # # query it\n",
    "# # query = \"What books were recommended in this podcast?\"\n",
    "# # docs = db.similarity_search(query)\n",
    "\n",
    "# # print results\n",
    "# # print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bff797ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The books recommended in this podcast were \"Operation Pedestal\" by Max Hastings, \"Into the Heart of Romans\" by N. T. Wright, and \"Man Hunt: The 12-Day Chase for Lincoln's Killer\" by James Swanson.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.document_loaders import TextLoader\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "\n",
    "class Genie:\n",
    "\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.loader = TextLoader(self.file_path)\n",
    "        self.documents = self.loader.load()\n",
    "        self.texts = self.text_split(self.documents)\n",
    "        self.vectordb = self.embeddings(self.texts)\n",
    "        retriever = VectorStoreRetriever(vectorstore=self.vectordb)\n",
    "        self.genie = RetrievalQA.from_llm(llm=OpenAI(), retriever=retriever)\n",
    "\n",
    "    @staticmethod\n",
    "    def text_split(documents: TextLoader):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        return texts\n",
    "\n",
    "    @staticmethod\n",
    "    def embeddings(texts: List[Document]):\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vectordb = Chroma.from_documents(texts, embeddings)\n",
    "        return vectordb\n",
    "\n",
    "    def ask(self, query: str):\n",
    "        return self.genie.run(query)\n",
    "\n",
    "\n",
    "genie = Genie(\"transcript.txt\")\n",
    "print(genie.ask(\"What books were recommended in this podcast?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66507c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61f6ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_path = \"transcript.txt\"\n",
    "loader = TextLoader(file_path)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = loader.load()\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "vectorstore = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "\n",
    "template = \"\"\"What books were recommended in this podcast?\"\"\"\n",
    "\n",
    "chat = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough()\n",
    "    | RunnableLambda(lambda x: chat.run(x))\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba4decbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain import hub\n",
    "from langchain_community.utils.openai_functions import (\n",
    "    convert_pydantic_to_openai_function,\n",
    ")\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.chains.openai_functions import create_structured_output_runnable\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "    \"\"\"A book.\"\"\"\n",
    "    title: str = Field(description=\"Title of the book\")\n",
    "    author: str = Field(description=\"Author of the book\")\n",
    "\n",
    "class Books(BaseModel):\n",
    "    \"\"\"A list of books.\"\"\"\n",
    "    books: List[Book] = Field(description=\"A list of books\")\n",
    "\n",
    "\n",
    "openai_functions = [convert_pydantic_to_openai_function(Book)]\n",
    "\n",
    "\n",
    "def embeddings(texts: List[Document]):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectordb = Chroma.from_documents(texts, embeddings)\n",
    "    return vectordb\n",
    "\n",
    "prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "\n",
    "file_path = \"transcript.txt\"\n",
    "loader = TextLoader(file_path)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = loader.load()\n",
    "texts = text_splitter.split_documents(documents)\n",
    "vectordb = embeddings(texts)\n",
    "\n",
    "retriever = VectorStoreRetriever(vectorstore=vectordb)\n",
    "# chain = create_stuff_documents_chain(\n",
    "#     model, prompt\n",
    "# )\n",
    "chain = create_structured_output_runnable(Books, model, prompt)\n",
    "chain = create_retrieval_chain(retriever, chain)\n",
    "# chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "result = chain.invoke({\"input\": \"What books were recommended in this podcast?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b567dd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What books were recommended in this podcast?',\n",
       " 'context': [Document(page_content=\"Hastings book. He's one of my favorite military historians. It's called Operation pedestal and for you, military history buffs who listen to Ezra really phenomenal storytelling about a pivotal convoy to save Malta in 1942 when it was under siege. Just incredible cast of characters and remarkable level of heroism. And it's a really tremendous book. The next one is a brand new book by N. T. Wright, who's a theologian. And it's called Into the Heart of Romans. And this is for your theology buffs who are Ezra who listened to your show Ezra. And it really is making a really interesting argument that the book of Romans, this pivotal book and the New Testament has been in some important ways misinterpreted. And that a more proper interpretation of Romans is one that actually has a more radical call to virtue. And then the next book is Back to Your History Buffs. And it's called Man Hunt, 12 day chase for Lincoln's Killer. And it's by James Swanson. And if you pick it up, you start reading\", metadata={'source': 'transcript.txt'}),\n",
       "  Document(page_content=\"Hastings book. He's one of my favorite military historians. It's called Operation pedestal and for you, military history buffs who listen to Ezra really phenomenal storytelling about a pivotal convoy to save Malta in 1942 when it was under siege. Just incredible cast of characters and remarkable level of heroism. And it's a really tremendous book. The next one is a brand new book by N. T. Wright, who's a theologian. And it's called Into the Heart of Romans. And this is for your theology buffs who are Ezra who listened to your show Ezra. And it really is making a really interesting argument that the book of Romans, this pivotal book and the New Testament has been in some important ways misinterpreted. And that a more proper interpretation of Romans is one that actually has a more radical call to virtue. And then the next book is Back to Your History Buffs. And it's called Man Hunt, 12 day chase for Lincoln's Killer. And it's by James Swanson. And if you pick it up, you start reading\", metadata={'source': 'transcript.txt'}),\n",
       "  Document(page_content=\"Hastings book. He's one of my favorite military historians. It's called Operation pedestal and for you, military history buffs who listen to Ezra really phenomenal storytelling about a pivotal convoy to save Malta in 1942 when it was under siege. Just incredible cast of characters and remarkable level of heroism. And it's a really tremendous book. The next one is a brand new book by N. T. Wright, who's a theologian. And it's called Into the Heart of Romans. And this is for your theology buffs who are Ezra who listened to your show Ezra. And it really is making a really interesting argument that the book of Romans, this pivotal book and the New Testament has been in some important ways misinterpreted. And that a more proper interpretation of Romans is one that actually has a more radical call to virtue. And then the next book is Back to Your History Buffs. And it's called Man Hunt, 12 day chase for Lincoln's Killer. And it's by James Swanson. And if you pick it up, you start reading\", metadata={'source': 'transcript.txt'}),\n",
       "  Document(page_content=\"Hastings book. He's one of my favorite military historians. It's called Operation pedestal and for you, military history buffs who listen to Ezra really phenomenal storytelling about a pivotal convoy to save Malta in 1942 when it was under siege. Just incredible cast of characters and remarkable level of heroism. And it's a really tremendous book. The next one is a brand new book by N. T. Wright, who's a theologian. And it's called Into the Heart of Romans. And this is for your theology buffs who are Ezra who listened to your show Ezra. And it really is making a really interesting argument that the book of Romans, this pivotal book and the New Testament has been in some important ways misinterpreted. And that a more proper interpretation of Romans is one that actually has a more radical call to virtue. And then the next book is Back to Your History Buffs. And it's called Man Hunt, 12 day chase for Lincoln's Killer. And it's by James Swanson. And if you pick it up, you start reading\", metadata={'source': 'transcript.txt'})],\n",
       " 'answer': Books(books=[Book(title='Operation pedestal', author='Hastings'), Book(title='Into the Heart of Romans', author='N. T. Wright'), Book(title=\"Man Hunt, 12 day chase for Lincoln's Killer\", author='James Swanson')])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96d6ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd49546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Pedestal by Hastings\n",
      "Into the Heart of Romans by N. T. Wright\n",
      "Man Hunt: 12 Day Chase for Lincoln's Killer by James Swanson\n"
     ]
    }
   ],
   "source": [
    "for book in result['answer'].books:\n",
    "    print(f\"{book.title} by {book.author}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9400f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
